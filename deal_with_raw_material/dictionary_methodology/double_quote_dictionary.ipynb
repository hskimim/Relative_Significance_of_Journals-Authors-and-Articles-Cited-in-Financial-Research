{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../personal_pkgs/')\n",
    "\n",
    "import pandas as pd\n",
    "import oop_func as func\n",
    "import personal_pkg as ref\n",
    "import parsing_func as pars\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 저널 별 데이터를 모으자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_txt_ls = pars.journal_txt_ls('한국재무관리학회')\n",
    "sc_txt_ls = pars.journal_txt_ls('한국증권학회지')\n",
    "dr_txt_ls = pars.journal_txt_ls('한국파생상품학회')\n",
    "f_txt_ls = pars.journal_txt_ls('한국재무학회')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_path = [refer for i in fm_txt_ls for refer in i]\n",
    "f_path = [refer for i in f_txt_ls for refer in i]\n",
    "sc_path = [refer for i in sc_txt_ls for refer in i]\n",
    "dr_path = [refer for i in dr_txt_ls for refer in i]\n",
    "\n",
    "fm_sent_ls , fm_error_ls = pars.split_to_sent(fm_path)\n",
    "f_sent_ls , f_error_ls = pars.split_to_sent(f_path)\n",
    "sc_sent_ls , sc_error_ls = pars.split_to_sent(sc_path)\n",
    "dr_sent_ls , dr_error_ls = pars.split_to_sent(dr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11487, 7213, 9578, 8166)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fm_sent_ls) , len(f_sent_ls) , len(sc_sent_ls) , len(dr_sent_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 42, 78, 76)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fm_error_ls) , len(f_error_ls) , len(sc_error_ls) , len(dr_error_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_error_path_ls = [fm_error_ls[idx][1] for idx in range(len(fm_error_ls))]\n",
    "f_error_path_ls = [f_error_ls[idx][1] for idx in range(len(f_error_ls))]\n",
    "sc_error_path_ls = [sc_error_ls[idx][1] for idx in range(len(sc_error_ls))]\n",
    "dr_error_path_ls = [dr_error_ls[idx][1] for idx in range(len(dr_error_ls))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_error_df = pd.DataFrame(fm_error_path_ls)\n",
    "f_error_df = pd.DataFrame(f_error_path_ls)\n",
    "sc_error_df = pd.DataFrame(dr_error_path_ls)\n",
    "dr_error_df = pd.DataFrame(sc_error_path_ls)\n",
    "\n",
    "pd.concat([fm_error_df,f_error_df,sc_error_df,dr_error_df]).to_csv('error_path.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `*_q_ls` : double quotation 이 있는 sentence. 분석 가능한 문장이라고 간주해 dictionary 를 형성하는 데 사용된다.\n",
    "- `*_nq_ls` : quotation 이 없는 sentence. 불안정한 문장, 즉, 딕셔너리를 형성하는데에는 부적합하다고 간주한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of double quotation line : 0.8318969269609123\n",
      "total length of double quote lines: 9556\n",
      "total length of lines: 11487\n",
      "ratio of double quotation line : 0.6974906418965756\n",
      "total length of double quote lines: 5031\n",
      "total length of lines: 7213\n",
      "ratio of double quotation line : 0.3106076425140948\n",
      "total length of double quote lines: 2975\n",
      "total length of lines: 9578\n",
      "ratio of double quotation line : 0.24222385500857213\n",
      "total length of double quote lines: 1978\n",
      "total length of lines: 8166\n"
     ]
    }
   ],
   "source": [
    "fm_q_ls , fm_nq_ls = pars.show_quote_and_unquote(fm_sent_ls)\n",
    "f_q_ls , f_nq_ls = pars.show_quote_and_unquote(f_sent_ls)\n",
    "sc_q_ls , sc_nq_ls = pars.show_quote_and_unquote(sc_sent_ls)\n",
    "dr_q_ls , dr_nq_ls = pars.show_quote_and_unquote(dr_sent_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_ip_ls = pars.make_imperfect_ls(fm_nq_ls)\n",
    "f_ip_ls = pars.make_imperfect_ls(f_nq_ls)\n",
    "sc_ip_ls = pars.make_imperfect_ls(sc_nq_ls)\n",
    "dr_ip_ls = pars.make_imperfect_ls(dr_nq_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 딕셔너리 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminate the duplicated paper name\n",
      "(9556, 4)\n",
      "(8067, 5)\n",
      "eliminate the duplicated paper name\n",
      "(5031, 4)\n",
      "(4317, 5)\n",
      "eliminate the duplicated paper name\n",
      "(2975, 4)\n",
      "(2338, 5)\n",
      "eliminate the duplicated paper name\n",
      "(1978, 4)\n",
      "(1735, 5)\n"
     ]
    }
   ],
   "source": [
    "fm_df,unique_fm_df = pars.make_dictionary(fm_q_ls)\n",
    "f_df,unique_f_df = pars.make_dictionary(f_q_ls)\n",
    "sc_df,unique_sc_df = pars.make_dictionary(sc_q_ls)\n",
    "dr_df,unique_dr_df = pars.make_dictionary(dr_q_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_df['from'] = ['한국재무관리학회' for _ in range(len(fm_df))]\n",
    "f_df['from'] = ['한국재무학회' for _ in range(len(f_df))]\n",
    "sc_df['from'] = ['한국증권학회' for _ in range(len(sc_df))]\n",
    "dr_df['from'] = ['한국파생상품학회' for _ in range(len(dr_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19540, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_df = pd.concat([fm_df,f_df,sc_df,dr_df],ignore_index=True)\n",
    "dictionary_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 점수 기반해서 quotation 이 없는 sentence 에 대해서 논문 이름을 추출한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19540, 5)\n",
      "(14609, 6)\n"
     ]
    }
   ],
   "source": [
    "idx_ls = []\n",
    "print(dictionary_df.shape)\n",
    "\n",
    "for idx,val in enumerate(dictionary_df['paper'].tolist()) :\n",
    "    if val not in [i[1] for i in idx_ls] :\n",
    "        idx_ls.append((idx,val))\n",
    "\n",
    "quote_df = dictionary_df.iloc[[i[0] for i in idx_ls]]\n",
    "quote_df.reset_index(inplace=True)\n",
    "print(quote_df.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.9 라는 similarity score 를 기준으로 삼아서, double quoatation 이 없는 문장의 paper name 을 catch 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of dictionary is 14609.. the cost of function is proportional with it\n",
      "0\n",
      "4000\n",
      "8000\n",
      "12000\n",
      "the length of dictionary is 14609.. the cost of function is proportional with it\n",
      "0\n",
      "4000\n",
      "8000\n",
      "12000\n",
      "the length of dictionary is 14609.. the cost of function is proportional with it\n",
      "0\n",
      "4000\n",
      "8000\n",
      "12000\n",
      "the length of dictionary is 14609.. the cost of function is proportional with it\n",
      "0\n",
      "4000\n",
      "8000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "fm_catch_paper = pars.catch_the_paper_under_similarity_score(quote_df,fm_ip_ls,score=0.9)\n",
    "f_catch_paper = pars.catch_the_paper_under_similarity_score(quote_df,f_ip_ls,score=0.9)\n",
    "sc_catch_paper = pars.catch_the_paper_under_similarity_score(quote_df,sc_ip_ls,score=0.9)\n",
    "dr_catch_paper = pars.catch_the_paper_under_similarity_score(quote_df,dr_ip_ls,score=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 109 2732 417\n"
     ]
    }
   ],
   "source": [
    "print(len(fm_catch_paper),\n",
    "len(f_catch_paper),\n",
    "len(sc_catch_paper),\n",
    "len(dr_catch_paper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총합친 것도 필요하지만, 우리에게 필요한 것은 저널별 데이터이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_detect_ls = [i[0] for i in fm_catch_paper]\n",
    "f_detect_ls = [i[0] for i in f_catch_paper]\n",
    "sc_detect_ls = [i[0] for i in sc_catch_paper]\n",
    "dr_detect_ls = [i[0] for i in dr_catch_paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9720"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_paper_name_ls = dictionary_df[dictionary_df['from'] == '한국재무관리학회']['paper'].tolist()\n",
    "fm_paper_name_ls = fm_paper_name_ls + fm_detect_ls\n",
    "len(fm_paper_name_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5140"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_paper_name_ls = dictionary_df[dictionary_df['from'] == '한국재무학회']['paper'].tolist()\n",
    "f_paper_name_ls = f_paper_name_ls + f_detect_ls\n",
    "len(f_paper_name_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5707"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_paper_name_ls = dictionary_df[dictionary_df['from'] == '한국증권학회']['paper'].tolist()\n",
    "sc_paper_name_ls = sc_paper_name_ls + sc_detect_ls\n",
    "len(sc_paper_name_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2395"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_paper_name_ls = dictionary_df[dictionary_df['from'] == '한국파생상품학회']['paper'].tolist()\n",
    "dr_paper_name_ls = dr_paper_name_ls + dr_detect_ls\n",
    "len(dr_paper_name_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "fm_final_df = pd.DataFrame(columns=['author','year','paper','journal'])\n",
    "\n",
    "for idx in range(len(fm_paper_name_ls)) : \n",
    "    if len(fm_final_df) % 4000 == 0 : print(len(fm_final_df))\n",
    "    append_df = quote_df[quote_df['paper'] == fm_paper_name_ls[idx]]\n",
    "    fm_final_df = pd.concat([fm_final_df,append_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_final_df.to_csv('fm_base_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "f_final_df = pd.DataFrame(columns=['author','year','paper','journal'])\n",
    "\n",
    "for idx in range(len(f_paper_name_ls)) : \n",
    "    if len(f_final_df) % 4000 == 0 : print(len(f_final_df))\n",
    "    append_df = quote_df[quote_df['paper'] == f_paper_name_ls[idx]]\n",
    "    f_final_df = pd.concat([f_final_df,append_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_final_df.to_csv('f_base_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "sc_final_df = pd.DataFrame(columns=['author','year','paper','journal'])\n",
    "\n",
    "for idx in range(len(sc_paper_name_ls)) : \n",
    "    if len(sc_final_df) % 4000 == 0 : print(len(sc_final_df))\n",
    "    append_df = quote_df[quote_df['paper'] == sc_paper_name_ls[idx]]\n",
    "    sc_final_df = pd.concat([sc_final_df,append_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_final_df.to_csv('sc_base_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "dr_final_df = pd.DataFrame(columns=['author','year','paper','journal'])\n",
    "\n",
    "for idx in range(len(dr_paper_name_ls)) : \n",
    "    if len(dr_final_df) % 4000 == 0 : print(len(dr_final_df))\n",
    "    append_df = quote_df[quote_df['paper'] == dr_paper_name_ls[idx]]\n",
    "    dr_final_df = pd.concat([dr_final_df,append_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_final_df.to_csv('dr_base_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### catch_paper_name_ls 은 저널에 관계없이 non-quoted sentence 에서 총 어떤 논문 이름을 잡았는지에 대한 데이터를 담은 리스트이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3422"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catch_paper_name_ls = [i[0] for i in fm_catch_paper]+\\\n",
    "[i[0] for i in f_catch_paper]+\\\n",
    "[i[0] for i in sc_catch_paper]+\\\n",
    "[i[0] for i in dr_catch_paper]\n",
    "len(catch_paper_name_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- final_paper_name_ls 는 paper name 으로 uniquely indexing 해주기 전의 double quotation sentence 를 담은 dataframe 이다.\n",
    "- non double quotation sentence 데이터에서 추출한 catch_paper_name_ls를 dictionary_df 의 인덱스와 합치면 총 논문 이름에 대한 리스트를 얻게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22962"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_paper_name_ls = dictionary_df['paper'].tolist()\n",
    "final_paper_name_ls = base_paper_name_ls + catch_paper_name_ls\n",
    "len(final_paper_name_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_paper_name_ls 의 논문 이름 포맷은 전적으로 quote_df 를 따른다. 이에 따라서, Counting 을 할 때, quote_df 의 포맷을 유지하면서 `expanding` 시켜준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4000\n",
      "8000\n",
      "12000\n",
      "16000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "base_df = pd.DataFrame(columns=['author','year','paper','journal'])\n",
    "\n",
    "for idx in range(len(final_paper_name_ls)) : \n",
    "    if len(base_df) % 4000 == 0 : print(len(base_df))\n",
    "    append_df = quote_df[quote_df['paper'] == final_paper_name_ls[idx]]\n",
    "    base_df = pd.concat([base_df,append_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.to_csv('base_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `base_df` 는 저널에 관계없이 전체 논문에 대해서 similarity score를 기반으로 최대한 merge 한 데이터들을 담은 dataframe 이다.\n",
    "- `{}_base_df` 는 {} 에 붙은 alias 에 따라 특정 논문에 대한 base_df 이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
