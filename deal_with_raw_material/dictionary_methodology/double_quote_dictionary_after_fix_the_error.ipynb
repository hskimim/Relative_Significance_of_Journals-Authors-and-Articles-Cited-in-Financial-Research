{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../personal_pkgs/')\n",
    "\n",
    "import pandas as pd\n",
    "import oop_func as func\n",
    "import personal_pkg as ref\n",
    "import parsing_func as pars\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 저널 별 데이터를 모으자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_txt_ls = pars.journal_txt_ls('한국재무관리학회')\n",
    "sc_txt_ls = pars.journal_txt_ls('한국증권학회지')\n",
    "dr_txt_ls = pars.journal_txt_ls('한국파생상품학회')\n",
    "f_txt_ls = pars.journal_txt_ls('한국재무학회')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_path = [refer for i in fm_txt_ls for refer in i]\n",
    "f_path = [refer for i in f_txt_ls for refer in i]\n",
    "sc_path = [refer for i in sc_txt_ls for refer in i]\n",
    "dr_path = [refer for i in dr_txt_ls for refer in i]\n",
    "\n",
    "fm_sent_ls , fm_error_ls = pars.split_to_sent(fm_path)\n",
    "f_sent_ls , f_error_ls = pars.split_to_sent(f_path)\n",
    "sc_sent_ls , sc_error_ls = pars.split_to_sent(sc_path)\n",
    "dr_sent_ls , dr_error_ls = pars.split_to_sent(dr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12227, 9176, 12309, 8655)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fm_sent_ls) , len(f_sent_ls) , len(sc_sent_ls) , len(dr_sent_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 3, 24, 58)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fm_error_ls) , len(f_error_ls) , len(sc_error_ls) , len(dr_error_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 Error term 을 Fix 하는 코드를 추가 삽입한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_error_path_ls = [fm_error_ls[idx][1] for idx in range(len(fm_error_ls))]\n",
    "f_error_path_ls = [f_error_ls[idx][1] for idx in range(len(f_error_ls))]\n",
    "sc_error_path_ls = [sc_error_ls[idx][1] for idx in range(len(sc_error_ls))]\n",
    "dr_error_path_ls = [dr_error_ls[idx][1] for idx in range(len(dr_error_ls))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vol23_no3_213.txt 는 무슨 방법을 써도 안되더라.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vol23_no3_213.txt'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([i[1].split(\"/\")[-1] for i in fm_error_ls + f_error_ls + sc_error_ls + dr_error_ls]).difference(os.listdir('error_solved_file/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국재무관리연구\n",
      "The number of original error files was 76, but it was reduced to 76.\n",
      "The Number of final error file is 0\n",
      "The length of sentences which I fixed the error is 4181\n",
      "한국재무학회\n",
      "The number of original error files was 3, but it was reduced to 0.\n",
      "The Number of final error file is 2\n",
      "The length of sentences which I fixed the error is 0\n",
      "한국증권학회지\n",
      "The number of original error files was 24, but it was reduced to 24.\n",
      "The Number of final error file is 0\n",
      "The length of sentences which I fixed the error is 2867\n",
      "한국파생상품학회\n",
      "The number of original error files was 58, but it was reduced to 58.\n",
      "The Number of final error file is 0\n",
      "The length of sentences which I fixed the error is 3942\n"
     ]
    }
   ],
   "source": [
    "print('한국재무관리연구')\n",
    "fm_fix_error_ls = pars.fix_the_error_file(fm_error_path_ls)\n",
    "print('한국재무학회')\n",
    "f_fix_error_ls = pars.fix_the_error_file(f_error_path_ls)\n",
    "print('한국증권학회지')\n",
    "sc_fix_error_ls = pars.fix_the_error_file(sc_error_path_ls)\n",
    "print('한국파생상품학회')\n",
    "dr_fix_error_ls = pars.fix_the_error_file(dr_error_path_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 나와있는 것도 있지만, 대부분 이미지 파일이기 때문에 깨져 있는 경우가 많다. 아래는 재무관리연구학회에서 에러가 났던 파일을 소생시켜 파싱한 리스트이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['참고문헌 검얀무 검인무 검잔웅 검찬웅 “한국 “한국 일본 일본 미국 미국 주식시장의 주식시장의 정보전달 정보전달 : : KOSDAQ KOSDAQ ]ASDAQ ]ASDAQ NAS- NAS- DAQ과 DAQ과 거래소시장을 거래소시장을 중심으로 중심으로 증권학화지 증권학회',\n",
       " '제28집 제28집 (2001) (2001)',\n",
       " '김찬웅 김찬웅 문규현 문규현 홍정효 홍정효? “한미일 “한미일 주가지수선물자료를 주가지수선물자료를 이용한 이용한 국제자본시장들간의 국제자본시장들간의 정보 정보 이전효과에 이전효과에 대한 대한 실증적 실증적 연구 연구 증권학회지 증권학회지 제 제 31집 31집 (2002) (2002)',\n",
       " '문규현 문규현 홍정효 홍정효 “아사아-태평양지역국가틀간의 “아사아-태평양지역국가틀간의 상호의존성에 상호의존성에 관한 관한 연구\" 연구\" 재무관리연구 재무관리연구  제 제 20권 20권 제 제 2호 2호  (2003) (2003)',\n",
       " '장국현 장국현 “주식시장 “주식시장 동조화와 동조화와 다운사이드 다운사이드 리스크 리스크 재무연구 재무연구 저IU5 저IU5 권 권 저H 저H 호 호 (2002) (2002)',\n",
       " 'Bekaert Beka앙t Geert Geert and and Campbell Campbell R. R. Harvey H따vey “Emerging “Emerging equity equity market market volatility \" volatility \" ] ] OUTηαl OUTηαl of of Financial Financial Economics Economics   43 43 (1997) (1997)',\n",
       " 'Bemdt Bemdt E. E. K. K. B. B. H. H. Hall Hall R. R. E. E. Hall Hall and and ]. ]. A. A. Hausman Hausman c. c. “Estimation “Estimation and and Infe Infe - - rence rence in in Nonlinear Nonlinear Structural Structural Models \" Models \" Joumα1 Joumα1 of of Economic Economic and and Social Social M없sure- Meαrsure- 한국 채권현물시장에 대한 미국 채권현물시장의 가격발견기능 연구 149 ment (1974)',\n",
       " 'Baillie R. and Bollerslev T. “The Message in Daily Exchange Rates : A Conditio - 1퍼1 Variance Tale \" ]oumal cf Business αîd Econαnic Staα!stics 7 (19없)',\n",
       " 'Bollerslev T. “Generalized Autoregressive Conditional Heteroskedasticity \" Jourηal of Econometrics 31 (1986)',\n",
       " 'Bollerslev T. “Modeling the Coherence in Short-Run Nominal Exchange Rate : A Multivariate Generalized ARCH Model \" π-ze Rα)iew of Economics and StJαistics 72 (1992)',\n",
       " 'Engle R. F. T. lto and W. Lin “Meteor Showers or Heatwaves? Heteroskedasticι Intra-Day Volatility in the Foreign Exchange Market \" Econometrica 58 (1990)',\n",
       " 'Eun Cheol S. and Sangdal Shim “Intemational Transmission of Stock Market Movements \" ]oumαl of Financial and QuantitJαtive Anαlysis  24(2) (1989)',\n",
       " 'Engle Robert F. “Estimates of the Variance of U. S. Inflation Based upon the ARCH Model \" ]OLlTηal of Money Credit and Banking 15(3) (1982).',\n",
       " 'Engle Robert F. and Granger c. “Cointegration and Error Correction Represen- tation Estimation and Testing \" Econometrica 55 (1987)',\n",
       " 'French Kenneth R. G. William Schwert and Robert F. Stambaugh “Expected Stock Retums and Volatility \" ]oumαl of Finα7cial Economics 19 (1987)',\n",
       " 'Hamao Yasushi Ronald W. Masulis and Victor Ng “Correlations in 단ice Changes and Volatility across Intemational Stock Markets \" Review of Finαncial Studies  3 (1990)',\n",
       " 'Ito. T. R. F. Engle and W. -L. Lin “Where Does the Meteor Shower Come From? \" ]ournαl of Intemational Economics 32 (1992)',\n",
       " 'Karolyi G. A. and R. St띠tz “Why Do Markets Move Together? An Investigation of U.S.-Ja뼈n Stock Retum Comwerænts \" ]ournal cf Finanæ  II (3) (1996)',\n",
       " 'Lin W. R. Engle and K. lto “Do Bulls and Bears Move Across Borders? Intemational Transmission of Stock Retums and Volatility \" Review of Financiαl Studies 7 (1994)',\n",
       " 'Ng Angela “Volatility spillover effects from J apan and the US to the Pacific- 財務管理硏究 150 150 Basin \" Basin \" Joumα1 Jourηα1 of of 1 Intenlαtionα1 nternationα1 Money Money and and Finance Finance  19 19 (2000) (2000)',\n",
       " 'Phillips Phillips P. P. C. C. B B and and P. P. Perron Perron “Testing “Testing for for a a Unit Unit Root Root in in Time Time Series Series Regres- Regres- sions \" sions \" Biometrika Biometrika 75 75 (1988) (1988)',\n",
       " 'Ross Ross S.A. S.A. “Information “Information and and Volatility Volatility : : The The No-Arbitrage No-Arbitrage Martingle Martingle to to Timing Timing and and Resolution Resolution Irrelevancy \" Irrelevancy \" Journα1 Journα1 of of Finance Finance   44 44 (1989) (1989)',\n",
       " 'Susmel Susmel Paul Paul and and Robert Robert F. F. Engle Engle “Hourly “Ho따ly volatility volat괴ity spillovers spillovers between between intemational intemational equity equity markets \" markets \" Journal ] oumα1 of of Intemαtional International Money Money and and Finance Finance 13 13 (1994) (1994)',\n",
       " 'THE KOREAN JOURNAL OF FINANCIAL MANAGEMENT Volume 21 Number 2 Dec. 2004',\n",
       " '참고문헌 고광수 고광수 노석균 노석균 “제 “제 지수에 지수에 나타나는 나타나는 월별계절성 월별계절성 연구 연구 : : 미국 미국 일본 일본 영국 영국 및 및 아시안 아시안 NICs와의 NICs와의 바교 바교 재무연구 재무연구 제6호 제6호 1993.',\n",
       " '1993.',\n",
       " '김성민 김성민 “배당락일의 “배당락일의 주가행태에 주가행태에 관한 관한 효율성 효율성 검증 검 증 재무연구 재무연구 제 제 14호 14호 1997.',\n",
       " '1997.',\n",
       " '김성민 김성민 “현금배당락조치 “현금배당락조치 폐지이후 폐지이후 배당락일의 배당락일의 주가행태 주가행태 재무관리논총 재무관리논총 제 제 9권 9권 제 제 1호 1호 2003 2003',\n",
       " '김태혁 김태혁 신용걸 신용걸 “주식배당의 “주식배당의 공사효과와 공시효과와 정보전달효과에 정보전달효과에 관한 관한 연구 연구 증권학회지 증권학회지 제 제 15집 15집 1993 1993']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_fix_error_ls[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_sent_ls += fm_fix_error_ls\n",
    "f_sent_ls += f_fix_error_ls\n",
    "sc_sent_ls += sc_fix_error_ls\n",
    "dr_sent_ls += dr_fix_error_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16408, 9176, 15176, 12597)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fm_sent_ls) , len(f_sent_ls) , len(sc_sent_ls) , len(dr_sent_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `*_q_ls` : double quotation 이 있는 sentence. 분석 가능한 문장이라고 간주해 dictionary 를 형성하는 데 사용된다.\n",
    "- `*_nq_ls` : quotation 이 없는 sentence. 불안정한 문장, 즉, 딕셔너리를 형성하는데에는 부적합하다고 간주한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of double quotation line : 0.6311555338859093\n",
      "total length of double quote lines: 10356\n",
      "total length of lines: 16408\n",
      "ratio of double quotation line : 0.7450959023539668\n",
      "total length of double quote lines: 6837\n",
      "total length of lines: 9176\n",
      "ratio of double quotation line : 0.20314971006852925\n",
      "total length of double quote lines: 3083\n",
      "total length of lines: 15176\n",
      "ratio of double quotation line : 0.19615781535286178\n",
      "total length of double quote lines: 2471\n",
      "total length of lines: 12597\n"
     ]
    }
   ],
   "source": [
    "fm_q_ls , fm_nq_ls = pars.show_quote_and_unquote(fm_sent_ls)\n",
    "f_q_ls , f_nq_ls = pars.show_quote_and_unquote(f_sent_ls)\n",
    "sc_q_ls , sc_nq_ls = pars.show_quote_and_unquote(sc_sent_ls)\n",
    "dr_q_ls , dr_nq_ls = pars.show_quote_and_unquote(dr_sent_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_ip_ls = pars.make_imperfect_ls(fm_nq_ls)\n",
    "f_ip_ls = pars.make_imperfect_ls(f_nq_ls)\n",
    "sc_ip_ls = pars.make_imperfect_ls(sc_nq_ls)\n",
    "dr_ip_ls = pars.make_imperfect_ls(dr_nq_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 딕셔너리 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminate the duplicated paper name\n",
      "(10356, 4)\n",
      "(8729, 5)\n",
      "eliminate the duplicated paper name\n",
      "(6837, 4)\n",
      "(5852, 5)\n",
      "eliminate the duplicated paper name\n",
      "(3083, 4)\n",
      "(2443, 5)\n",
      "eliminate the duplicated paper name\n",
      "(2471, 4)\n",
      "(2182, 5)\n"
     ]
    }
   ],
   "source": [
    "fm_df,unique_fm_df = pars.make_dictionary(fm_q_ls)\n",
    "f_df,unique_f_df = pars.make_dictionary(f_q_ls)\n",
    "sc_df,unique_sc_df = pars.make_dictionary(sc_q_ls)\n",
    "dr_df,unique_dr_df = pars.make_dictionary(dr_q_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_df['from'] = ['한국재무관리학회' for _ in range(len(fm_df))]\n",
    "f_df['from'] = ['한국재무학회' for _ in range(len(f_df))]\n",
    "sc_df['from'] = ['한국증권학회' for _ in range(len(sc_df))]\n",
    "dr_df['from'] = ['한국파생상품학회' for _ in range(len(dr_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22747, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_df = pd.concat([fm_df,f_df,sc_df,dr_df],ignore_index=True)\n",
    "dictionary_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 점수 기반해서 quotation 이 없는 sentence 에 대해서 논문 이름을 추출한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22747, 5)\n",
      "(17040, 6)\n"
     ]
    }
   ],
   "source": [
    "idx_ls = []\n",
    "print(dictionary_df.shape)\n",
    "\n",
    "for idx,val in enumerate(dictionary_df['paper'].tolist()) :\n",
    "    if val not in [i[1] for i in idx_ls] :\n",
    "        idx_ls.append((idx,val))\n",
    "\n",
    "quote_df = dictionary_df.iloc[[i[0] for i in idx_ls]]\n",
    "quote_df.reset_index(inplace=True)\n",
    "print(quote_df.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.9 라는 similarity score 를 기준으로 삼아서, double quoatation 이 없는 문장의 paper name 을 catch 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of dictionary is 17040.. the cost of function is proportional with it\n",
      "0\n",
      "4000\n",
      "8000\n",
      "12000\n",
      "16000\n",
      "the length of dictionary is 17040.. the cost of function is proportional with it\n",
      "0\n",
      "4000\n",
      "8000\n",
      "12000\n",
      "16000\n",
      "the length of dictionary is 17040.. the cost of function is proportional with it\n",
      "0\n",
      "4000\n",
      "8000\n",
      "12000\n",
      "16000\n",
      "the length of dictionary is 17040.. the cost of function is proportional with it\n",
      "0\n",
      "4000\n",
      "8000\n",
      "12000\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "fm_catch_paper = pars.catch_the_paper_under_similarity_score(quote_df,fm_ip_ls,score=0.9)\n",
    "f_catch_paper = pars.catch_the_paper_under_similarity_score(quote_df,f_ip_ls,score=0.9)\n",
    "sc_catch_paper = pars.catch_the_paper_under_similarity_score(quote_df,sc_ip_ls,score=0.9)\n",
    "dr_catch_paper = pars.catch_the_paper_under_similarity_score(quote_df,dr_ip_ls,score=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540 208 4248 707\n"
     ]
    }
   ],
   "source": [
    "print(len(fm_catch_paper),\n",
    "len(f_catch_paper),\n",
    "len(sc_catch_paper),\n",
    "len(dr_catch_paper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총합친 것도 필요하지만, 우리에게 필요한 것은 저널별 데이터이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_detect_ls = [i[0] for i in fm_catch_paper]\n",
    "f_detect_ls = [i[0] for i in f_catch_paper]\n",
    "sc_detect_ls = [i[0] for i in sc_catch_paper]\n",
    "dr_detect_ls = [i[0] for i in dr_catch_paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10896"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_paper_name_ls = dictionary_df[dictionary_df['from'] == '한국재무관리학회']['paper'].tolist()\n",
    "fm_paper_name_ls = fm_paper_name_ls + fm_detect_ls\n",
    "len(fm_paper_name_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7045"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_paper_name_ls = dictionary_df[dictionary_df['from'] == '한국재무학회']['paper'].tolist()\n",
    "f_paper_name_ls = f_paper_name_ls + f_detect_ls\n",
    "len(f_paper_name_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7331"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_paper_name_ls = dictionary_df[dictionary_df['from'] == '한국증권학회']['paper'].tolist()\n",
    "sc_paper_name_ls = sc_paper_name_ls + sc_detect_ls\n",
    "len(sc_paper_name_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3178"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_paper_name_ls = dictionary_df[dictionary_df['from'] == '한국파생상품학회']['paper'].tolist()\n",
    "dr_paper_name_ls = dr_paper_name_ls + dr_detect_ls\n",
    "len(dr_paper_name_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "fm_final_df = pd.DataFrame(columns=['author','year','paper','journal'])\n",
    "\n",
    "for idx in range(len(fm_paper_name_ls)) : \n",
    "    if len(fm_final_df) % 4000 == 0 : print(len(fm_final_df))\n",
    "    append_df = quote_df[quote_df['paper'] == fm_paper_name_ls[idx]]\n",
    "    fm_final_df = pd.concat([fm_final_df,append_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_final_df.to_csv('fm_base_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "f_final_df = pd.DataFrame(columns=['author','year','paper','journal'])\n",
    "\n",
    "for idx in range(len(f_paper_name_ls)) : \n",
    "    if len(f_final_df) % 4000 == 0 : print(len(f_final_df))\n",
    "    append_df = quote_df[quote_df['paper'] == f_paper_name_ls[idx]]\n",
    "    f_final_df = pd.concat([f_final_df,append_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_final_df.to_csv('f_base_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "sc_final_df = pd.DataFrame(columns=['author','year','paper','journal'])\n",
    "\n",
    "for idx in range(len(sc_paper_name_ls)) : \n",
    "    if len(sc_final_df) % 4000 == 0 : print(len(sc_final_df))\n",
    "    append_df = quote_df[quote_df['paper'] == sc_paper_name_ls[idx]]\n",
    "    sc_final_df = pd.concat([sc_final_df,append_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_final_df.to_csv('sc_base_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "dr_final_df = pd.DataFrame(columns=['author','year','paper','journal'])\n",
    "\n",
    "for idx in range(len(dr_paper_name_ls)) : \n",
    "    if len(dr_final_df) % 4000 == 0 : print(len(dr_final_df))\n",
    "    append_df = quote_df[quote_df['paper'] == dr_paper_name_ls[idx]]\n",
    "    dr_final_df = pd.concat([dr_final_df,append_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_final_df.to_csv('dr_base_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### catch_paper_name_ls 은 저널에 관계없이 non-quoted sentence 에서 총 어떤 논문 이름을 잡았는지에 대한 데이터를 담은 리스트이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5703"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catch_paper_name_ls = [i[0] for i in fm_catch_paper]+\\\n",
    "[i[0] for i in f_catch_paper]+\\\n",
    "[i[0] for i in sc_catch_paper]+\\\n",
    "[i[0] for i in dr_catch_paper]\n",
    "len(catch_paper_name_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- final_paper_name_ls 는 paper name 으로 uniquely indexing 해주기 전의 double quotation sentence 를 담은 dataframe 이다.\n",
    "- non double quotation sentence 데이터에서 추출한 catch_paper_name_ls를 dictionary_df 의 인덱스와 합치면 총 논문 이름에 대한 리스트를 얻게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28450"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_paper_name_ls = dictionary_df['paper'].tolist()\n",
    "final_paper_name_ls = base_paper_name_ls + catch_paper_name_ls\n",
    "len(final_paper_name_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_paper_name_ls 의 논문 이름 포맷은 전적으로 quote_df 를 따른다. 이에 따라서, Counting 을 할 때, quote_df 의 포맷을 유지하면서 `expanding` 시켜준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4000\n",
      "8000\n",
      "12000\n",
      "16000\n",
      "20000\n",
      "24000\n",
      "28000\n"
     ]
    }
   ],
   "source": [
    "base_df = pd.DataFrame(columns=['author','year','paper','journal'])\n",
    "\n",
    "for idx in range(len(final_paper_name_ls)) : \n",
    "    if len(base_df) % 4000 == 0 : print(len(base_df))\n",
    "    append_df = quote_df[quote_df['paper'] == final_paper_name_ls[idx]]\n",
    "    base_df = pd.concat([base_df,append_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.to_csv('base_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `base_df` 는 저널에 관계없이 전체 논문에 대해서 similarity score를 기반으로 최대한 merge 한 데이터들을 담은 dataframe 이다.\n",
    "- `{}_base_df` 는 {} 에 붙은 alias 에 따라 특정 논문에 대한 base_df 이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
